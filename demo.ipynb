{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cc9227c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/factordb/lib/python3.10/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Testing the examples from the documentation.\"\"\"\n",
    "\n",
    "# Author: Trevor Stephens <trevorstephens.com>\n",
    "#\n",
    "# License: BSD 3 clause\n",
    "import sys\n",
    "sys.path.append('gplearn')\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import load_diabetes, load_breast_cancer\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils._testing import assert_almost_equal\n",
    "from sklearn.utils.validation import check_random_state\n",
    "\n",
    "from gplearn.genetic import SymbolicClassifier, SymbolicRegressor\n",
    "from gplearn.genetic import SymbolicTransformer\n",
    "from gplearn.functions import make_function\n",
    "\n",
    "\n",
    "def test_symbolic_regressor():\n",
    "    \"\"\"Check that SymbolicRegressor example works\"\"\"\n",
    "\n",
    "    rng = check_random_state(0)\n",
    "    X_train = rng.uniform(-1, 1, 100).reshape(50, 2)\n",
    "    y_train = X_train[:, 0] ** 2 - X_train[:, 1] ** 2 + X_train[:, 1] - 1\n",
    "    X_test = rng.uniform(-1, 1, 100).reshape(50, 2)\n",
    "    y_test = X_test[:, 0] ** 2 - X_test[:, 1] ** 2 + X_test[:, 1] - 1\n",
    "\n",
    "    est_gp = SymbolicRegressor(population_size=5000, generations=20,\n",
    "                               stopping_criteria=0.01, p_crossover=0.7,\n",
    "                               p_subtree_mutation=0.1, p_hoist_mutation=0.05,\n",
    "                               p_point_mutation=0.1, max_samples=0.9,\n",
    "                               parsimony_coefficient=0.01, random_state=0)\n",
    "    est_gp.fit(X_train, y_train)\n",
    "\n",
    "    assert(len(est_gp._programs) == 7)\n",
    "    expected = 'sub(add(-0.999, X1), mul(sub(X1, X0), add(X0, X1)))'\n",
    "    assert(est_gp.__str__() == expected)\n",
    "    assert_almost_equal(est_gp.score(X_test, y_test), 0.99999, decimal=5)\n",
    "    dot_data = est_gp._program.export_graphviz()\n",
    "    expected = ('digraph program {\\nnode [style=filled]\\n0 [label=\"sub\", '\n",
    "                'fillcolor=\"#136ed4\"] ;\\n1 [label=\"add\", fillcolor=\"#136ed4\"] '\n",
    "                ';\\n2 [label=\"-0.999\", fillcolor=\"#60a6f6\"] ;\\n3 [label=\"X1\", '\n",
    "                'fillcolor=\"#60a6f6\"] ;\\n1 -> 3 ;\\n1 -> 2 ;\\n4 [label=\"mul\", '\n",
    "                'fillcolor=\"#136ed4\"] ;\\n5 [label=\"sub\", fillcolor=\"#136ed4\"] '\n",
    "                ';\\n6 [label=\"X1\", fillcolor=\"#60a6f6\"] ;\\n7 [label=\"X0\", '\n",
    "                'fillcolor=\"#60a6f6\"] ;\\n5 -> 7 ;\\n5 -> 6 ;\\n8 [label=\"add\", '\n",
    "                'fillcolor=\"#136ed4\"] ;\\n9 [label=\"X0\", fillcolor=\"#60a6f6\"] '\n",
    "                ';\\n10 [label=\"X1\", fillcolor=\"#60a6f6\"] ;\\n8 -> 10 ;\\n8 -> 9 '\n",
    "                ';\\n4 -> 8 ;\\n4 -> 5 ;\\n0 -> 4 ;\\n0 -> 1 ;\\n}')\n",
    "    assert(dot_data == expected)\n",
    "    assert(est_gp._program.parents == {'method': 'Crossover',\n",
    "                                       'parent_idx': 1555,\n",
    "                                       'parent_nodes': range(1, 4),\n",
    "                                       'donor_idx': 78,\n",
    "                                       'donor_nodes': []})\n",
    "    idx = est_gp._program.parents['donor_idx']\n",
    "    fade_nodes = est_gp._program.parents['donor_nodes']\n",
    "    assert(est_gp._programs[-2][idx].__str__() == 'add(-0.999, X1)')\n",
    "    assert_almost_equal(est_gp._programs[-2][idx].fitness_, 0.351803319075)\n",
    "    dot_data = est_gp._programs[-2][idx].export_graphviz(fade_nodes=fade_nodes)\n",
    "    expected = ('digraph program {\\nnode [style=filled]\\n0 [label=\"add\", '\n",
    "                'fillcolor=\"#136ed4\"] ;\\n1 [label=\"-0.999\", '\n",
    "                'fillcolor=\"#60a6f6\"] ;\\n2 [label=\"X1\", fillcolor=\"#60a6f6\"] '\n",
    "                ';\\n0 -> 2 ;\\n0 -> 1 ;\\n}')\n",
    "    assert(dot_data == expected)\n",
    "    idx = est_gp._program.parents['parent_idx']\n",
    "    fade_nodes = est_gp._program.parents['parent_nodes']\n",
    "    expected = 'sub(sub(X1, 0.939), mul(sub(X1, X0), add(X0, X1)))'\n",
    "    assert(est_gp._programs[-2][idx].__str__() == expected)\n",
    "    assert_almost_equal(est_gp._programs[-2][idx].fitness_, 0.17080204042)\n",
    "    dot_data = est_gp._programs[-2][idx].export_graphviz(fade_nodes=fade_nodes)\n",
    "    expected = ('digraph program {\\nnode [style=filled]\\n0 [label=\"sub\", '\n",
    "                'fillcolor=\"#136ed4\"] ;\\n1 [label=\"sub\", fillcolor=\"#cecece\"] '\n",
    "                ';\\n2 [label=\"X1\", fillcolor=\"#cecece\"] ;\\n3 [label=\"0.939\", '\n",
    "                'fillcolor=\"#cecece\"] ;\\n1 -> 3 ;\\n1 -> 2 ;\\n4 [label=\"mul\", '\n",
    "                'fillcolor=\"#136ed4\"] ;\\n5 [label=\"sub\", fillcolor=\"#136ed4\"] '\n",
    "                ';\\n6 [label=\"X1\", fillcolor=\"#60a6f6\"] ;\\n7 [label=\"X0\", '\n",
    "                'fillcolor=\"#60a6f6\"] ;\\n5 -> 7 ;\\n5 -> 6 ;\\n8 [label=\"add\", '\n",
    "                'fillcolor=\"#136ed4\"] ;\\n9 [label=\"X0\", fillcolor=\"#60a6f6\"] '\n",
    "                ';\\n10 [label=\"X1\", fillcolor=\"#60a6f6\"] ;\\n8 -> 10 ;\\n8 -> 9 '\n",
    "                ';\\n4 -> 8 ;\\n4 -> 5 ;\\n0 -> 4 ;\\n0 -> 1 ;\\n}')\n",
    "    assert(dot_data == expected)\n",
    "\n",
    "\n",
    "def test_symbolic_transformer():\n",
    "    \"\"\"Check that SymbolicTransformer example works\"\"\"\n",
    "\n",
    "    rng = check_random_state(0)\n",
    "    diabetes = load_diabetes()\n",
    "    perm = rng.permutation(diabetes.target.size)\n",
    "    diabetes.data = diabetes.data[perm]\n",
    "    diabetes.target = diabetes.target[perm]\n",
    "\n",
    "    est = Ridge()\n",
    "    est.fit(diabetes.data[:300, :], diabetes.target[:300])\n",
    "    assert_almost_equal(est.score(diabetes.data[300:, :],\n",
    "                                  diabetes.target[300:]),\n",
    "                        desired=0.43406, decimal=5)\n",
    "\n",
    "    function_set = ['add', 'sub', 'mul', 'div', 'sqrt', 'log',\n",
    "                    'abs', 'neg', 'inv', 'max', 'min']\n",
    "    gp = SymbolicTransformer(generations=20, population_size=2000,\n",
    "                             hall_of_fame=100, n_components=10,\n",
    "                             function_set=function_set,\n",
    "                             parsimony_coefficient=0.0005,\n",
    "                             max_samples=0.9,\n",
    "                             random_state=0)\n",
    "    gp.fit(diabetes.data[:300, :], diabetes.target[:300])\n",
    "\n",
    "    gp_features = gp.transform(diabetes.data)\n",
    "    new_diabetes = np.hstack((diabetes.data, gp_features))\n",
    "\n",
    "    est = Ridge()\n",
    "    est.fit(new_diabetes[:300, :], diabetes.target[:300])\n",
    "    assert_almost_equal(est.score(new_diabetes[300:, :],\n",
    "                                  diabetes.target[300:]),\n",
    "                        desired=0.53368, decimal=5)\n",
    "\n",
    "\n",
    "def test_custom_functions():\n",
    "    \"\"\"Test the custom programs example works\"\"\"\n",
    "\n",
    "    rng = check_random_state(0)\n",
    "    diabetes = load_diabetes()\n",
    "    perm = rng.permutation(diabetes.target.size)\n",
    "    diabetes.data = diabetes.data[perm]\n",
    "    diabetes.target = diabetes.target[perm]\n",
    "\n",
    "    def logic(x1, x2, x3, x4):\n",
    "        return np.where(x1 > x2, x3, x4)\n",
    "\n",
    "    logical = make_function(function=logic,\n",
    "                            name='logical',\n",
    "                            arity=4)\n",
    "\n",
    "    function_set = ['add', 'sub', 'mul', 'div', logical]\n",
    "    gp = SymbolicTransformer(generations=2, population_size=2000,\n",
    "                             hall_of_fame=100, n_components=10,\n",
    "                             function_set=function_set,\n",
    "                             parsimony_coefficient=0.0005,\n",
    "                             max_samples=0.9, random_state=0)\n",
    "\n",
    "    gp.fit(diabetes.data[:300, :], diabetes.target[:300])\n",
    "\n",
    "    expected = ('add(X3, logical(div(X5, sub(X5, X5)), '\n",
    "                'add(X9, -0.621), X8, X4))')\n",
    "    assert(gp._programs[0][3].__str__() == expected)\n",
    "\n",
    "    dot_data = gp._programs[0][3].export_graphviz()\n",
    "    expected = ('digraph program {\\nnode [style=filled]\\n0 [label=\"add\", '\n",
    "                'fillcolor=\"#136ed4\"] ;\\n1 [label=\"X3\", fillcolor=\"#60a6f6\"] ;'\n",
    "                '\\n2 [label=\"logical\", fillcolor=\"#136ed4\"] ;\\n3 [label=\"div\",'\n",
    "                ' fillcolor=\"#136ed4\"] ;\\n4 [label=\"X5\", fillcolor=\"#60a6f6\"] '\n",
    "                ';\\n5 [label=\"sub\", fillcolor=\"#136ed4\"] ;\\n6 [label=\"X5\", '\n",
    "                'fillcolor=\"#60a6f6\"] ;\\n7 [label=\"X5\", fillcolor=\"#60a6f6\"] '\n",
    "                ';\\n5 -> 7 ;\\n5 -> 6 ;\\n3 -> 5 ;\\n3 -> 4 ;\\n8 [label=\"add\", '\n",
    "                'fillcolor=\"#136ed4\"] ;\\n9 [label=\"X9\", fillcolor=\"#60a6f6\"] '\n",
    "                ';\\n10 [label=\"-0.621\", fillcolor=\"#60a6f6\"] ;\\n8 -> 10 ;\\n8 '\n",
    "                '-> 9 ;\\n11 [label=\"X8\", fillcolor=\"#60a6f6\"] ;\\n12 '\n",
    "                '[label=\"X4\", fillcolor=\"#60a6f6\"] ;\\n2 -> 12 ;\\n2 -> 11 ;\\n2 '\n",
    "                '-> 8 ;\\n2 -> 3 ;\\n0 -> 2 ;\\n0 -> 1 ;\\n}')\n",
    "    assert(dot_data == expected)\n",
    "\n",
    "\n",
    "def test_classifier_comparison():\n",
    "    \"\"\"Test the classifier comparison example works\"\"\"\n",
    "\n",
    "    X, y = make_classification(n_features=2, n_redundant=0, n_informative=2,\n",
    "                               random_state=1, n_clusters_per_class=1)\n",
    "    rng = np.random.RandomState(2)\n",
    "    X += 2 * rng.uniform(size=X.shape)\n",
    "    linearly_separable = (X, y)\n",
    "    datasets = [make_moons(noise=0.3, random_state=0),\n",
    "                make_circles(noise=0.2, factor=0.5, random_state=1),\n",
    "                linearly_separable]\n",
    "    scores = []\n",
    "    for ds in datasets:\n",
    "        X, y = ds\n",
    "        X = StandardScaler().fit_transform(X)\n",
    "        X_train, X_test, y_train, y_test = \\\n",
    "            train_test_split(X, y, test_size=.4, random_state=42)\n",
    "        clf = SymbolicClassifier(random_state=0)\n",
    "        clf.fit(X_train, y_train)\n",
    "        score = clf.score(X_test, y_test)\n",
    "        scores.append(('%.2f' % score).lstrip('0'))\n",
    "\n",
    "    assert(scores == ['.95', '.93', '.95'])\n",
    "\n",
    "\n",
    "def test_symbolic_classifier():\n",
    "    \"\"\"Check that SymbolicClassifier example works\"\"\"\n",
    "\n",
    "    rng = check_random_state(0)\n",
    "    cancer = load_breast_cancer()\n",
    "    perm = rng.permutation(cancer.target.size)\n",
    "    cancer.data = cancer.data[perm]\n",
    "    cancer.target = cancer.target[perm]\n",
    "\n",
    "    est = SymbolicClassifier(parsimony_coefficient=.01,\n",
    "                             feature_names=cancer.feature_names,\n",
    "                             random_state=1)\n",
    "    est.fit(cancer.data[:400], cancer.target[:400])\n",
    "\n",
    "    y_true = cancer.target[400:]\n",
    "    y_score = est.predict_proba(cancer.data[400:])[:, 1]\n",
    "    assert_almost_equal(roc_auc_score(y_true, y_score), 0.96937869822485212)\n",
    "\n",
    "    dot_data = est._program.export_graphviz()\n",
    "    expected = ('digraph program {\\nnode [style=filled]\\n0 [label=\"sub\", '\n",
    "                'fillcolor=\"#136ed4\"] ;\\n1 [label=\"div\", fillcolor=\"#136ed4\"] '\n",
    "                ';\\n2 [label=\"worst fractal dimension\", fillcolor=\"#60a6f6\"] '\n",
    "                ';\\n3 [label=\"mean concave points\", fillcolor=\"#60a6f6\"] '\n",
    "                ';\\n1 -> 3 ;\\n1 -> 2 ;\\n4 [label=\"mul\", fillcolor=\"#136ed4\"] '\n",
    "                ';\\n5 [label=\"mean concave points\", fillcolor=\"#60a6f6\"] ;\\n6 '\n",
    "                '[label=\"area error\", fillcolor=\"#60a6f6\"] ;\\n4 -> 6 ;\\n4 -> '\n",
    "                '5 ;\\n0 -> 4 ;\\n0 -> 1 ;\\n}')\n",
    "    assert(dot_data == expected)\n",
    "\n",
    "\n",
    "test_symbolic_regressor()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "factordb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
